# Frequently Asked Questions (FAQ) About GGUF Loader

This FAQ answers common questions to help you troubleshoot and get the best experience with GGUF Loader.

## What is GGUF Loader?

GGUF Loader is an open-source local AI model loader and assistant that supports GGUF-format models, enabling offline AI chats with features like a floating button and extensible addons.

## How do I load a model?

Click the **Load Model** button in GGUF Loader.  
A window will open allowing you to select the **folder** containing your GGUF model files.  
Select the folder and click **OK** — the model will then load.

## How does the floating button work?

The floating button **automatically activates as soon as the model loads**.  
Whenever you **select any text anywhere on your desktop**, the floating button appears near the selection.  
Click it to chat instantly with your local AI assistant.

## What if the floating button doesn't appear?

- Confirm that a model is loaded — the floating button only works when a model is active.  
- Check your operating system permissions for overlay or accessibility features.  
- Restart GGUF Loader if needed.

## Can I add my own addons?

Yes! GGUF Loader supports an addon system to extend features.  
See the [Addon Guide](creating-addons-in-gguf-loader.md) for instructions on creating and installing addons.

## How do I enable GPU acceleration?

GPU acceleration requires configuring compatible backends such as CUDA or OpenCL.  
Refer to the advanced setup wiki page for detailed instructions.

## Where can I get help or report issues?

Join the community Discord or open an issue on the GGUF Loader GitHub repository.

---

If your question isn't listed here, feel free to add it or contact the maintainers directly.

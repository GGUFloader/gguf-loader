<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>GGUF Loader â€“ Run Mistral & LLaMA Locally</title>
  <meta name="description" content="Run Mistral, LLaMA, and other GGUF-format models locally on Windows with a simple GUI. No Python. No internet. 100% offline AI assistant.">
  <style>
    body {
      font-family: sans-serif;
      margin: 0;
      padding: 0;
      background: #f9f9f9;
      color: #222;
      line-height: 1.6;
    }
    .container {
      max-width: 800px;
      margin: auto;
      padding: 2rem;
    }
    h1 { font-size: 2.5rem; margin-bottom: 1rem; }
    h2 { margin-top: 2rem; }
    a.button {
      display: inline-block;
      background: #007acc;
      color: white;
      padding: 0.75rem 1.5rem;
      margin-top: 1rem;
      text-decoration: none;
      border-radius: 8px;
    }
    code {
      background: #eee;
      padding: 0.2rem 0.4rem;
      border-radius: 4px;
    }
    .feature-list li {
      margin-bottom: 0.5rem;
    }
    footer {
      margin-top: 4rem;
      font-size: 0.9rem;
      color: #666;
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>GGUF Loader</h1>
    <p><strong>Run Mistral, LLaMA, DeepSeek, and other GGUF-format models offline â€” with zero setup.</strong></p>
    <p>No Python. No command line. No cloud. Just click, load, and chat with your favorite LLMs locally on Windows.</p>

    <a class="button" href="https://github.com/hussainnazary2/gguf-loader/releases">ğŸ”½ Download GGUF Loader</a>

    <h2>ğŸš€ Features</h2>
    <ul class="feature-list">
      <li>ğŸ§  Run Mistral, LLaMA, DeepSeek, TinyLLaMA and more</li>
      <li>âœ… 100% Offline â€” No Internet or API keys</li>
      <li>ğŸ–¥ï¸ Clean Windows GUI â€” No terminal required</li>
      <li>âš¡ Lightweight and fast</li>
      <li>ğŸ” Privacy-first: your data stays local</li>
    </ul>

    <h2>ğŸ¯ Use Cases</h2>
    <ul>
      <li>Build an offline smart assistant</li>
      <li>Run AI in low-connectivity environments (schools, remote areas)</li>
      <li>Use AI safely in legal, private, or medical work</li>
      <li>Experiment with local models without technical setup</li>
    </ul>

    <h2>ğŸ“¥ How It Works</h2>
    <ol>
      <li>Download the app</li>
      <li>Load a GGUF model from HuggingFace</li>
      <li>Start chatting â€” fully offline</li>
    </ol>

    <h2>ğŸ’¡ Recommended Models</h2>
    <ul>
      <li><a href="https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF">Mistral 7B Instruct</a></li>
      <li><a href="https://huggingface.co/TheBloke/Llama-3-8B-Instruct-GGUF">LLaMA 3 Instruct</a></li>
      <li><a href="https://huggingface.co/TheBloke/Deepseek-Coder-6.7B-GGUF">DeepSeek Coder</a></li>
    </ul>

    <h2>ğŸ“· Coming Soon</h2>
    <p>Screenshots and GIF demo of the UI.</p>

    <footer>
      Built with â¤ï¸ by <a href="https://github.com/hussainnazary2">Hussain</a> â€¢ <a href="https://github.com/hussainnazary2/gguf-loader">View Source on GitHub</a>
    </footer>
  </div>
</body>
</html>
